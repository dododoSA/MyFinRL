{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-LLC/FinRL-Library/blob/master/FinRL_single_stock_trading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Idd1jem0TnST"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Single Stock Trading\n",
    "\n",
    "Tutorials to use OpenAI DRL to trade single stock in one Jupyter Notebook | Presented at NeurIPS 2020: Deep RL Workshop\n",
    "\n",
    "* This blog is based on our paper: FinRL: A Deep Reinforcement Learning Library for Automated Stock Trading in Quantitative Finance, presented at NeurIPS 2020: Deep RL Workshop.\n",
    "* Check out medium blog for detailed explanations: https://towardsdatascience.com/finrl-for-quantitative-finance-tutorial-for-single-stock-trading-37d6d7c30aac\n",
    "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
    "* **Pytorch Version** \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vglc_9N5-KZ"
   },
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ex2ord116AbP"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M1eLhMW36cLi"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eimeRv06YoK"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: single stock trading for AAPL\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n",
    "\n",
    "We use Apple Inc. stock: AAPL as an example throughout this article, because it is one of the most popular and profitable stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xD3f90UnTnSU"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBUcBKap-oII"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40axJBAP5mer",
    "outputId": "0e61993b-e962-4b70-a178-fe86404dd1ca"
   },
   "outputs": [],
   "source": [
    "## install finrl library\n",
    "#!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXyHD6ir5sxk"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QG17M4JwTnSZ"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0-0bsNMMTnSZ",
    "outputId": "e1c336ac-1280-4b16-b1d4-c2971d6667c2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akihi\\.conda\\envs\\RL\\lib\\site-packages\\pyfolio\\pos.py:27: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
      "  'Module \"zipline.assets\" not found; multipliers will not be applied'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "# 設定をインポート　定数をまとめてここで定義している\n",
    "from finrl.config import config\n",
    "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
    "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
    "from finrl.preprocessing.data import data_split\n",
    "from finrl.env.env_stocktrading import StockTradingEnv\n",
    "from finrl.model.models import DRLAgent\n",
    "from finrl.trade.backtest import BackTestStats, BaselineStats, BackTestPlot\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uIPbzYs1TnSd"
   },
   "outputs": [],
   "source": [
    "#Diable the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pos2IZAL54pp"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zp6lL6dZ53rX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBPM0sVvTnSg"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCGVmtGzjORf"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FBEiH5gOgMOx",
    "outputId": "de388576-0110-46f4-9257-dfe327b3eac5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2009-01-01'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py start_date is a string\n",
    "config.START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "sWLMNQ8CgMRx",
    "outputId": "f1864c8b-2b5c-4867-9122-ccf83ebc2902"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-12-01'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py end_date is a string\n",
    "config.END_DATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmFpuBEZhkF3"
   },
   "source": [
    "ticker_list is a list of stock tickers, in a single stock trading case, the list contains only 1 ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JtIFikNyTnSg",
    "outputId": "4c6a860f-6944-4728-984d-d0dc8d8f2c78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (2951, 8)\n"
     ]
    }
   ],
   "source": [
    "# Download and save the data in a pandas DataFrame:\n",
    "# endは含まない csvとかに保存はここではされない\n",
    "data_df = YahooDownloader(start_date = '2009-01-01',\n",
    "                          end_date = '2020-09-22',\n",
    "                          ticker_list = ['AAPL']).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8ZKQmw6TnSl",
    "outputId": "954cbef4-f75b-4d4b-80f2-195eb13954ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2951, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "Vi6D_ED6TnSs",
    "outputId": "2313cd51-596f-4a58-922b-5ec837bbcbda"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>2020-09-15</td>\n",
       "      <td>118.330002</td>\n",
       "      <td>118.830002</td>\n",
       "      <td>113.610001</td>\n",
       "      <td>115.168915</td>\n",
       "      <td>184642000</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>2020-09-16</td>\n",
       "      <td>115.230003</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>112.040001</td>\n",
       "      <td>111.769859</td>\n",
       "      <td>154679000</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2948</th>\n",
       "      <td>2020-09-17</td>\n",
       "      <td>109.720001</td>\n",
       "      <td>112.199997</td>\n",
       "      <td>108.709999</td>\n",
       "      <td>109.985611</td>\n",
       "      <td>178011000</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2949</th>\n",
       "      <td>2020-09-18</td>\n",
       "      <td>110.400002</td>\n",
       "      <td>110.879997</td>\n",
       "      <td>106.089996</td>\n",
       "      <td>106.496849</td>\n",
       "      <td>287104900</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2950</th>\n",
       "      <td>2020-09-21</td>\n",
       "      <td>104.540001</td>\n",
       "      <td>110.190002</td>\n",
       "      <td>103.099998</td>\n",
       "      <td>109.726448</td>\n",
       "      <td>195713800</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date        open        high         low       close     volume  \\\n",
       "2946  2020-09-15  118.330002  118.830002  113.610001  115.168915  184642000   \n",
       "2947  2020-09-16  115.230003  116.000000  112.040001  111.769859  154679000   \n",
       "2948  2020-09-17  109.720001  112.199997  108.709999  109.985611  178011000   \n",
       "2949  2020-09-18  110.400002  110.879997  106.089996  106.496849  287104900   \n",
       "2950  2020-09-21  104.540001  110.190002  103.099998  109.726448  195713800   \n",
       "\n",
       "       tic  day  \n",
       "2946  AAPL    1  \n",
       "2947  AAPL    2  \n",
       "2948  AAPL    3  \n",
       "2949  AAPL    4  \n",
       "2950  AAPL    0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWiqgpLzTnS3"
   },
   "source": [
    "<a id='3'></a>\n",
    "# Part 4. Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* FinRL uses a class **FeatureEngineer** to preprocess the data\n",
    "* Add **technical indicators**. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJ9zmxpRks41"
   },
   "source": [
    "class FeatureEngineer:\n",
    "Provides methods for preprocessing the stock price data\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        df: DataFrame\n",
    "            data downloaded from Yahoo API\n",
    "        feature_number : int\n",
    "            number of features we used\n",
    "        use_technical_indicator : boolean\n",
    "            we technical indicator or not\n",
    "        use_turbulence : boolean\n",
    "            use turbulence index or not\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    preprocess_data()\n",
    "        main method to do the feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHu7i-T_wRPc"
   },
   "source": [
    "<a id='3.1'></a>\n",
    "\n",
    "## 4.1 Technical Indicators\n",
    "* FinRL uses stockstats to calcualte technical indicators such as **Moving Average Convergence Divergence (MACD)**, **Relative Strength Index (RSI)**, **Average Directional Index (ADX)**, **Commodity Channel Index (CCI)** and other various indicators and stats.\n",
    "* **stockstats**: supplies a wrapper StockDataFrame based on the **pandas.DataFrame** with inline stock statistics/indicators support.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2RHwY1dHk09N",
    "outputId": "47be0df8-9e74-473e-f78e-9f267bcce3df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['macd', 'rsi_30', 'cci_30', 'dx_30']\n"
     ]
    }
   ],
   "source": [
    "## we store the stockstats technical indicator column names in config.py\n",
    "# config.py で設定したテクニカル指標を使用する\n",
    "tech_indicator_list=config.TECHNICAL_INDICATORS_LIST\n",
    "print(tech_indicator_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rImfGAfCkR8j",
    "outputId": "5b55c2c7-3217-49ad-95b7-d9af0ad91d7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['macd', 'rsi_30', 'cci_30', 'dx_30', 'kdjk', 'open_2_sma', 'boll', 'close_10.0_le_5_c', 'wr_10', 'dma', 'trix']\n"
     ]
    }
   ],
   "source": [
    "## user can add more technical indicators\n",
    "## check https://github.com/jealous/stockstats for different names\n",
    "# 以下のように追加できる\n",
    "tech_indicator_list=tech_indicator_list+['kdjk','open_2_sma','boll','close_10.0_le_5_c','wr_10','dma','trix']\n",
    "print(tech_indicator_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etvRo2rSwZPg"
   },
   "source": [
    "<a id='3.2'></a>\n",
    "## 4.2 Perform Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SAOsx0m-9u2k",
    "outputId": "6238a0f8-e0bb-4468-ec75-ab3381ea09a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n"
     ]
    }
   ],
   "source": [
    "# FeatureEngineer によって特徴量を作成　以下はデフォルトと同じ設定\n",
    "# use_technical_indicator: tech_indicator_listで設定したテクニカル指標を使用する\n",
    "# tech_indicator_list: stockstatsというパッケージを利用してテクニカル指標を計算するので、stockstatsに存在しないテクニカル指標は使えない\n",
    "# use_turbulence: 特徴量としてturbulence_indexを使用するかどうか\n",
    "# user_defined_feature: 自作の特徴量を使用するかどうか　自作の特徴量はFeatureEngineerのadd_user_defined_featureメソッド内に直接定義\n",
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = tech_indicator_list,\n",
    "                    use_turbulence=False,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "# 欠損値は直前の値と直後の値を使用して埋められる\n",
    "data_df = fe.preprocess_data(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "wytX_qwWMHP5",
    "outputId": "8113269b-39a0-462b-80b2-b8664eb27a66"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>kdjk</th>\n",
       "      <th>open_2_sma</th>\n",
       "      <th>boll</th>\n",
       "      <th>close_10.0_le_5_c</th>\n",
       "      <th>wr_10</th>\n",
       "      <th>dma</th>\n",
       "      <th>trix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>3.070357</td>\n",
       "      <td>3.133571</td>\n",
       "      <td>3.047857</td>\n",
       "      <td>2.625620</td>\n",
       "      <td>607541200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-130.870722</td>\n",
       "      <td>3.070357</td>\n",
       "      <td>2.625620</td>\n",
       "      <td>1.0</td>\n",
       "      <td>592.612167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.005509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>3.067143</td>\n",
       "      <td>3.251429</td>\n",
       "      <td>3.041429</td>\n",
       "      <td>2.791740</td>\n",
       "      <td>746015200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003727</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-126.880332</td>\n",
       "      <td>3.068750</td>\n",
       "      <td>2.708680</td>\n",
       "      <td>2.0</td>\n",
       "      <td>218.899551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.005509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>3.327500</td>\n",
       "      <td>3.435000</td>\n",
       "      <td>3.311071</td>\n",
       "      <td>2.909563</td>\n",
       "      <td>1181608400</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-95.755266</td>\n",
       "      <td>3.197322</td>\n",
       "      <td>2.775641</td>\n",
       "      <td>3.0</td>\n",
       "      <td>133.505133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-06</td>\n",
       "      <td>3.426786</td>\n",
       "      <td>3.470357</td>\n",
       "      <td>3.299643</td>\n",
       "      <td>2.861573</td>\n",
       "      <td>1289310400</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008591</td>\n",
       "      <td>84.866792</td>\n",
       "      <td>64.367902</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-77.814023</td>\n",
       "      <td>3.377143</td>\n",
       "      <td>2.797124</td>\n",
       "      <td>4.0</td>\n",
       "      <td>141.931537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.836218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-07</td>\n",
       "      <td>3.278929</td>\n",
       "      <td>3.303571</td>\n",
       "      <td>3.223571</td>\n",
       "      <td>2.799739</td>\n",
       "      <td>753048800</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006051</td>\n",
       "      <td>70.621528</td>\n",
       "      <td>6.035442</td>\n",
       "      <td>58.462756</td>\n",
       "      <td>-70.658498</td>\n",
       "      <td>3.352857</td>\n",
       "      <td>2.797647</td>\n",
       "      <td>5.0</td>\n",
       "      <td>156.347447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.653105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      open      high       low     close      volume   tic  day  \\\n",
       "0  2008-12-31  3.070357  3.133571  3.047857  2.625620   607541200  AAPL    2   \n",
       "1  2009-01-02  3.067143  3.251429  3.041429  2.791740   746015200  AAPL    4   \n",
       "2  2009-01-05  3.327500  3.435000  3.311071  2.909563  1181608400  AAPL    0   \n",
       "3  2009-01-06  3.426786  3.470357  3.299643  2.861573  1289310400  AAPL    1   \n",
       "4  2009-01-07  3.278929  3.303571  3.223571  2.799739   753048800  AAPL    2   \n",
       "\n",
       "       macd      rsi_30      cci_30       dx_30        kdjk  open_2_sma  \\\n",
       "0  0.000000  100.000000   66.666667  100.000000 -130.870722    3.070357   \n",
       "1  0.003727  100.000000   66.666667  100.000000 -126.880332    3.068750   \n",
       "2  0.008403  100.000000  100.000000  100.000000  -95.755266    3.197322   \n",
       "3  0.008591   84.866792   64.367902  100.000000  -77.814023    3.377143   \n",
       "4  0.006051   70.621528    6.035442   58.462756  -70.658498    3.352857   \n",
       "\n",
       "       boll  close_10.0_le_5_c       wr_10  dma      trix  \n",
       "0  2.625620                1.0  592.612167  0.0  1.005509  \n",
       "1  2.708680                2.0  218.899551  0.0  1.005509  \n",
       "2  2.775641                3.0  133.505133  0.0  1.000507  \n",
       "3  2.797124                4.0  141.931537  0.0  0.836218  \n",
       "4  2.797647                5.0  156.347447  0.0  0.653105  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwLhXo1cTnTQ"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Build Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1D1FlBdOL4b3"
   },
   "source": [
    "<a id='4.1'></a>\n",
    "## 5.1 Training & Trade data split\n",
    "* Training: 2009-01-01 to 2018-12-31\n",
    "* Trade: 2019-01-01 to 2020-09-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xNOdqfTKL6K-"
   },
   "outputs": [],
   "source": [
    "#train = data_split(data_df, start = config.START_DATE, end = config.START_TRADE_DATE)\n",
    "#trade = data_split(data_df, start = config.START_TRADE_DATE, end = config.END_DATE)\n",
    "# data_splitというとデータを分割するイメージだが、やっていることは指定した範囲でデータを切り出している\n",
    "# startはその日を含んでendはその日を含まない\n",
    "train = data_split(data_df, start = '2009-01-01', end = '2019-01-01')\n",
    "trade = data_split(data_df, start = '2019-01-01', end = '2020-09-23')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "KUxOshVouLXt"
   },
   "outputs": [],
   "source": [
    "# scikit-learnのpreprocessingを利用して特徴量の正規化を行う\n",
    "## data normalization, this part is optional, have little impact\n",
    "#feaures_list = list(train.columns)\n",
    "#feaures_list.remove('date')\n",
    "#feaures_list.remove('tic')\n",
    "#feaures_list.remove('close')\n",
    "#print(feaures_list)\n",
    "#from sklearn import preprocessing\n",
    "#data_normaliser = preprocessing.StandardScaler()\n",
    "#train[feaures_list] = data_normaliser.fit_transform(train[feaures_list])\n",
    "#trade[feaures_list] = data_normaliser.transform(trade[feaures_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMHyaSBBDGbe"
   },
   "source": [
    "<a id='4.2'></a>\n",
    "## 5.2 User-defined Environment: a simulation environment class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90V3S7cpDcQs"
   },
   "source": [
    "<a id='4.3'></a>\n",
    "## 5.3 Initialize Environment\n",
    "* **stock dimension**: the number of unique stock tickers we use\n",
    "* **hmax**: the maximum amount of shares to buy or sell\n",
    "* **initial amount**: the amount of money we use to trade in the begining\n",
    "* **transaction cost percentage**: a per share rate for every share trade\n",
    "* **tech_indicator_list**: a list of technical indicator names (modified from config.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OiH0xO96mGcL",
    "outputId": "490190d9-80dd-4ba0-c15f-2143cdd8341f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'kdjk',\n",
       " 'open_2_sma',\n",
       " 'boll',\n",
       " 'close_10.0_le_5_c',\n",
       " 'wr_10',\n",
       " 'dma',\n",
       " 'trix']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## we store the stockstats technical indicator column names in config.py\n",
    "## check https://github.com/jealous/stockstats for different names\n",
    "tech_indicator_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GnWOKS7DyGM7",
    "outputId": "09dff84b-19e1-4c4a-c40f-d5280195eaf4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the stock dimension is 1, because we only use the price data of AAPL.\n",
    "# 使用する銘柄の数\n",
    "len(train.tic.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ipJcnLvQGAba",
    "outputId": "dc32ebc6-2191-4541-99d2-7e9861da5df6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 1, State Space: 7\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "# balance + (銘柄ごとの株価) + (銘柄ごとの持ち株数) + (銘柄ごとのテクニカル指標)\n",
    "state_space = 1 + 2*stock_dimension + len(config.TECHNICAL_INDICATORS_LIST)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 100000, \n",
    "    \"transaction_cost_pct\": 0.001, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": config.TECHNICAL_INDICATORS_LIST, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"make_plots\": True\n",
    "}\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vmyi2IPnyEkP",
    "outputId": "a968a96a-a1ee-426e-eed8-ee74d20b9bb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdnzYtM1TnTW"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "BRFIZDw8TnTX"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zD1NHzGyTnTc"
   },
   "source": [
    "### Model Training: 5 models, A2C DDPG, PPO, TD3, SAC\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9CM5DeIr9GC"
   },
   "source": [
    "### Model 1: A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rOk-Mr73-EEq",
    "outputId": "1c56a5c6-91ad-4b81-dd07-24ae69e64c23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0002}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
    "model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DXHEidJh-E60",
    "outputId": "9ae1ede1-a8ee-4e56-c4f3-ef809e05d664"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/a2c\\a2c_6\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 194       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.43     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | -0.000308 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.13e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 265      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.44    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.00489 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.5e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 299      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.45    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -0.162   |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0128   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 322      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.45    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -0.0242  |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.000479 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 337      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.46    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.0318   |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.000991 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 346       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.46     |\n",
      "|    explained_variance | -3.48e+11 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 0.0091    |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.000155  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.46    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 8.7e-05  |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.2e-07  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.47    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 0.0492   |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.00417  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 367      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.48    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -0.304   |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.0127   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.47    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -0.747   |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.53     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.48    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.0392   |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.000917 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 367      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.48    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -0.00786 |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 7.94e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.49    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.00441  |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 3.72e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 376      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.5     |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -0.00288 |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 4.18e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 380      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.5     |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -0.0301  |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.00119  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 383       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.51     |\n",
      "|    explained_variance | -8.38e+09 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -0.000615 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 3.57e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 386      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.51    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -0.0217  |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.000236 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 388      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.52    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -0.00459 |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.000152 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 391      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.52    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -0.033   |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.00171  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 393      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -0.191   |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.0189   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 394      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 0.11     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.00894  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 395      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -0.0958  |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.00615  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 397      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | -0.09    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 0.332    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0589   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 398      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 0.151    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.00753  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 399      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 0.597    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.228    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 399      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -0.138   |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.0178   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 399      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 0.722    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.41     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 399       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.53     |\n",
      "|    explained_variance | -1.71e+12 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | 0.312     |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.0546    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 400      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 0.0193   |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.0137   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 401      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | -189     |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 1.31     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 2.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 401      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 0.0327   |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.00137  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 402      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -0.259   |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.193    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 403      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | -20.2    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 0.487    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.203    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 404      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.55    |\n",
      "|    explained_variance | -9.4e+04 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 0.289    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.0764   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 405      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.55    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 0.0973   |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.0783   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 405      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -0.26    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.038    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 405      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | -159     |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 1.15     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.744    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 406      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 0.411    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.173    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 407      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | -25.4    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -1.36    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.634    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 407      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | -136     |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -0.987   |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.69     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 406       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 50        |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.54     |\n",
      "|    explained_variance | -2.08e+03 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | 0.419     |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 0.098     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 407      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 0.186    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0424   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 407      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 0.669    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 408      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -0.748   |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.267    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 408      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -0.249   |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0576   |\n",
      "------------------------------------\n",
      "day: 2515, episode: 10\n",
      "begin_total_asset:100000.00\n",
      "end_total_asset:468645.94\n",
      "total_reward:368645.94\n",
      "total_cost: 3505.31\n",
      "total_trades: 2515\n",
      "Sharpe: 0.855\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 408      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -0.0659  |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.0222   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 409      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -1.81    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 409      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 0.295    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0564   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 409       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.53     |\n",
      "|    explained_variance | -9.56e+11 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | -0.335    |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.0753    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 410      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 3.95     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 13.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 410      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -0.386   |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0893   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 410      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 1.07     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 1.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 410      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | -16      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 2.42     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 2.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 410      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -2.1     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 1.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 410      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | -173     |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 1.21     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 1.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 410      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 0.05     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.000813 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 411      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 1        |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.574    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 411      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | -6.46    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 0.0705   |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.141    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 411      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -0.529   |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.149    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 412      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -2.54    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 4.63     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 411      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -0.18    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0143   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 411      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 0.876    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 411      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | -0.414   |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 0.0893   |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.00704  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 412      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 1.99     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 1.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 412      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | -139     |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 2.1      |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 3.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 411      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | -3.89    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -0.241   |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0673   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 412      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | -27.8    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 0.0707   |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.107    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 412      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 1.42     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.831    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 412      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | -114     |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -0.106   |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 413      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -5.27    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 9.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 413      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -0.621   |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.209    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 413      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 1.06     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.723    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 413      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | -29.6    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -0.173   |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.123    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 414      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -0.604   |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.394    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 414      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | -230     |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | 0.172    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.102    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 414       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 91        |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.53     |\n",
      "|    explained_variance | -8.96e+10 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | -0.298    |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.0344    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 414      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 0.0207   |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0101   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 414      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -0.0848  |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.201    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 415      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -0.79    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.862    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 415       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 96        |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.53     |\n",
      "|    explained_variance | -9.06e+03 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | 1.03      |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.64      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 415      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 0.0764   |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.0224   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 415      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | -0.0532  |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0223   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 415      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | 0.949    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.535    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 415      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | -0.293   |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0639   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 415      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 2.36     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 1.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 415      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -0.311   |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0633   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 415      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -0.801   |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.606    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 416      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -0.131   |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0467   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 416       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 106       |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.53     |\n",
      "|    explained_variance | -7.35e+12 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | 0.0106    |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.105     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 416      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 3.9      |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 9.61     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 416      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | -0.932   |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.234    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 416       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 110       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.54     |\n",
      "|    explained_variance | -2.04e+13 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | -1.75     |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 1.03      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 416      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | 0.657    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.175    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 416      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | -0.624   |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.223    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 416      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 0.511    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.192    |\n",
      "------------------------------------\n",
      "day: 2515, episode: 20\n",
      "begin_total_asset:100000.00\n",
      "end_total_asset:577115.97\n",
      "total_reward:477115.97\n",
      "total_cost: 3700.64\n",
      "total_trades: 2515\n",
      "Sharpe: 0.930\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 416      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 0.2      |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.0202   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 417      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -0.671   |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.299    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 417      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 0.455    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.193    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 417      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -0.742   |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.544    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 417      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.55    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -0.249   |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.197    |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                                tb_log_name='a2c',\n",
    "                                total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9upN8FI2r_X1"
   },
   "source": [
    "### Model 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gUFJlHsi-Ka-",
    "outputId": "1b7db70f-f740-401c-ab55-a567b4235e18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'buffer_size': 500000, 'learning_rate': 0.0001}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "DDPG_PARAMS = {\"batch_size\": 64, \"buffer_size\": 500000, \"learning_rate\": 0.0001}\n",
    "\n",
    "\n",
    "model_ddpg = agent.get_model(\"ddpg\",model_kwargs = DDPG_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I5J_Scwp-Nis",
    "outputId": "a538962d-33c8-44d3-94af-6ef61fc0d230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/ddpg\\ddpg_4\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 213      |\n",
      "|    time_elapsed    | 47       |\n",
      "|    total timesteps | 10064    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 349      |\n",
      "|    critic_loss     | 1.65e+03 |\n",
      "|    learning_rate   | 0.0001   |\n",
      "|    n_updates       | 7548     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 188      |\n",
      "|    time_elapsed    | 106      |\n",
      "|    total timesteps | 20128    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 207      |\n",
      "|    critic_loss     | 1.13e+03 |\n",
      "|    learning_rate   | 0.0001   |\n",
      "|    n_updates       | 17612    |\n",
      "---------------------------------\n",
      "day: 2515, episode: 30\n",
      "begin_total_asset:100000.00\n",
      "end_total_asset:100000.00\n",
      "total_reward:0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 180      |\n",
      "|    time_elapsed    | 167      |\n",
      "|    total timesteps | 30192    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 124      |\n",
      "|    critic_loss     | 796      |\n",
      "|    learning_rate   | 0.0001   |\n",
      "|    n_updates       | 27676    |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sve9WGvsC__"
   },
   "source": [
    "### Model 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BOjuycpS-Qvn",
    "outputId": "13ab0019-419b-4e6e-949d-c2617ae296b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.005, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.005,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G9hCHA8A-RSy",
    "outputId": "df865883-f3a8-42b2-951f-b129b44bd248"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/ppo\\ppo_5\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 739  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 2    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 605         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002051018 |\n",
      "|    clip_fraction        | 0.0342      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | -6.24e+12   |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00445    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.003      |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 0.00573     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 593          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038495697 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | -6.9e+11     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.00161      |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 0.00578      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 580          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006162131 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | -4.96        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.00661      |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.000986    |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 0.0706       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 573          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032270518 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -9.63e+13    |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.00651      |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.000302    |\n",
      "|    std                  | 0.991        |\n",
      "|    value_loss           | 0.0217       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 575       |\n",
      "|    iterations           | 6         |\n",
      "|    time_elapsed         | 21        |\n",
      "|    total_timesteps      | 12288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0026265 |\n",
      "|    clip_fraction        | 0.0101    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.41     |\n",
      "|    explained_variance   | -7.46     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.114     |\n",
      "|    n_updates            | 50        |\n",
      "|    policy_gradient_loss | -0.00185  |\n",
      "|    std                  | 0.987     |\n",
      "|    value_loss           | 0.23      |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 575           |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 24            |\n",
      "|    total_timesteps      | 14336         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00058488996 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.41         |\n",
      "|    explained_variance   | -25.1         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 0.346         |\n",
      "|    n_updates            | 60            |\n",
      "|    policy_gradient_loss | -0.00129      |\n",
      "|    std                  | 0.987         |\n",
      "|    value_loss           | 0.667         |\n",
      "-------------------------------------------\n",
      "day: 2515, episode: 40\n",
      "begin_total_asset:100000.00\n",
      "end_total_asset:446024.21\n",
      "total_reward:346024.21\n",
      "total_cost: 3262.62\n",
      "total_trades: 2513\n",
      "Sharpe: 0.813\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 571          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008990151 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -19.9        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.607        |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.000968    |\n",
      "|    std                  | 0.987        |\n",
      "|    value_loss           | 1.42         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 570           |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 32            |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0004336654 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.41         |\n",
      "|    explained_variance   | -39.9         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 0.83          |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -0.00015      |\n",
      "|    std                  | 0.988         |\n",
      "|    value_loss           | 1.78          |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 571            |\n",
      "|    iterations           | 10             |\n",
      "|    time_elapsed         | 35             |\n",
      "|    total_timesteps      | 20480          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -0.00013599807 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.41          |\n",
      "|    explained_variance   | -25.8          |\n",
      "|    learning_rate        | 0.0001         |\n",
      "|    loss                 | 1.09           |\n",
      "|    n_updates            | 90             |\n",
      "|    policy_gradient_loss | -0.000408      |\n",
      "|    std                  | 0.987          |\n",
      "|    value_loss           | 1.87           |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 573            |\n",
      "|    iterations           | 11             |\n",
      "|    time_elapsed         | 39             |\n",
      "|    total_timesteps      | 22528          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000120840064 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.41          |\n",
      "|    explained_variance   | -15.9          |\n",
      "|    learning_rate        | 0.0001         |\n",
      "|    loss                 | 0.986          |\n",
      "|    n_updates            | 100            |\n",
      "|    policy_gradient_loss | -0.000554      |\n",
      "|    std                  | 0.989          |\n",
      "|    value_loss           | 2.4            |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 571            |\n",
      "|    iterations           | 12             |\n",
      "|    time_elapsed         | 43             |\n",
      "|    total_timesteps      | 24576          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -0.00030871065 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.41          |\n",
      "|    explained_variance   | -6.99          |\n",
      "|    learning_rate        | 0.0001         |\n",
      "|    loss                 | 0.405          |\n",
      "|    n_updates            | 110            |\n",
      "|    policy_gradient_loss | -0.000645      |\n",
      "|    std                  | 0.988          |\n",
      "|    value_loss           | 1.02           |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 572          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032108366 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -10.3        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.716        |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0011      |\n",
      "|    std                  | 0.99         |\n",
      "|    value_loss           | 1.62         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 573          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013420259 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -27.8        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.2          |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.000956    |\n",
      "|    std                  | 0.99         |\n",
      "|    value_loss           | 2.16         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 573           |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 53            |\n",
      "|    total_timesteps      | 30720         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0012247608 |\n",
      "|    clip_fraction        | 0.00825       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.41         |\n",
      "|    explained_variance   | -16           |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 1.17          |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | -0.00255      |\n",
      "|    std                  | 0.991         |\n",
      "|    value_loss           | 2.28          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 574           |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 57            |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00074709725 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.41         |\n",
      "|    explained_variance   | -15           |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 1.13          |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | -0.00111      |\n",
      "|    std                  | 0.992         |\n",
      "|    value_loss           | 2.43          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 573          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 60           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054521225 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -16.6        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.32         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 2.68         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 572          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 64           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016879165 |\n",
      "|    clip_fraction        | 0.00698      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -1.84        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.612        |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00134     |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 1.46         |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 573            |\n",
      "|    iterations           | 19             |\n",
      "|    time_elapsed         | 67             |\n",
      "|    total_timesteps      | 38912          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -0.00027401638 |\n",
      "|    clip_fraction        | 0.000537       |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.41          |\n",
      "|    explained_variance   | -4.21          |\n",
      "|    learning_rate        | 0.0001         |\n",
      "|    loss                 | 1.77           |\n",
      "|    n_updates            | 180            |\n",
      "|    policy_gradient_loss | -0.000322      |\n",
      "|    std                  | 0.991          |\n",
      "|    value_loss           | 2.83           |\n",
      "--------------------------------------------\n",
      "day: 2515, episode: 50\n",
      "begin_total_asset:100000.00\n",
      "end_total_asset:563157.15\n",
      "total_reward:463157.15\n",
      "total_cost: 3360.44\n",
      "total_trades: 2515\n",
      "Sharpe: 0.876\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 573           |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 71            |\n",
      "|    total_timesteps      | 40960         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0012193236 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.41         |\n",
      "|    explained_variance   | -7.16         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 2.02          |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | -0.000566     |\n",
      "|    std                  | 0.992         |\n",
      "|    value_loss           | 3.06          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 573          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004030024 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -9.24        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.03         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.000151    |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 3.24         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 574          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 78           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026192493 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -14.4        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.51         |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.000785    |\n",
      "|    std                  | 0.991        |\n",
      "|    value_loss           | 3.29         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 574          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 81           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049888496 |\n",
      "|    clip_fraction        | 0.00981      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -10.3        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.947        |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 1.77         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 574         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002904572 |\n",
      "|    clip_fraction        | 0.00332     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | -10.8       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.51        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 3.09        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 574          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 89           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006656252 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -12.2        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.7          |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 3.26         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 573        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 92         |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00420923 |\n",
      "|    clip_fraction        | 0.0338     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.41      |\n",
      "|    explained_variance   | -14.3      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.33       |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.00246   |\n",
      "|    std                  | 0.995      |\n",
      "|    value_loss           | 3.44       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 574        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 96         |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00701874 |\n",
      "|    clip_fraction        | 0.00547    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.41      |\n",
      "|    explained_variance   | -19        |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.33       |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.00219   |\n",
      "|    std                  | 0.995      |\n",
      "|    value_loss           | 4.01       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 574          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 99           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014625596 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -43.3        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.51         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | 0.000112     |\n",
      "|    std                  | 0.996        |\n",
      "|    value_loss           | 2.65         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 574          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 103          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005261799 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -13.4        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.25         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    std                  | 0.994        |\n",
      "|    value_loss           | 2.39         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 574           |\n",
      "|    iterations           | 30            |\n",
      "|    time_elapsed         | 106           |\n",
      "|    total_timesteps      | 61440         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022315234 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.41         |\n",
      "|    explained_variance   | -17.9         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 1.21          |\n",
      "|    n_updates            | 290           |\n",
      "|    policy_gradient_loss | -0.000306     |\n",
      "|    std                  | 0.994         |\n",
      "|    value_loss           | 2.88          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 574          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 110          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031911102 |\n",
      "|    clip_fraction        | 0.0462       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -18.1        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.5          |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 3.12         |\n",
      "------------------------------------------\n",
      "day: 2515, episode: 60\n",
      "begin_total_asset:100000.00\n",
      "end_total_asset:567142.12\n",
      "total_reward:467142.12\n",
      "total_cost: 3399.02\n",
      "total_trades: 2515\n",
      "Sharpe: 0.900\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 574          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 114          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006229258 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -18.3        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.845        |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 2.86         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 575         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005728555 |\n",
      "|    clip_fraction        | 0.019       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | -28.9       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.76        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00144    |\n",
      "|    std                  | 0.995       |\n",
      "|    value_loss           | 3.66        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 575          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 121          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032627955 |\n",
      "|    clip_fraction        | 0.00957      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -10.7        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.869        |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    std                  | 0.994        |\n",
      "|    value_loss           | 1.53         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 575          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 124          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032826215 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -17          |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.999        |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 3.03         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 575          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 128          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039871596 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -18.5        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.49         |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 3.3          |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 574      |\n",
      "|    iterations           | 37       |\n",
      "|    time_elapsed         | 131      |\n",
      "|    total_timesteps      | 75776    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.002502 |\n",
      "|    clip_fraction        | 0.0291   |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.41    |\n",
      "|    explained_variance   | -13.9    |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 1.25     |\n",
      "|    n_updates            | 360      |\n",
      "|    policy_gradient_loss | -0.00252 |\n",
      "|    std                  | 0.992    |\n",
      "|    value_loss           | 3.46     |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 575          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 135          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012120326 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -18.2        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.96         |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.000356    |\n",
      "|    std                  | 0.989        |\n",
      "|    value_loss           | 3.73         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 575         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004097385 |\n",
      "|    clip_fraction        | 0.0388      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | -58         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.07        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    std                  | 0.987       |\n",
      "|    value_loss           | 1.97        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 575         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004228631 |\n",
      "|    clip_fraction        | 0.00698     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | -11.9       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.33        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0019     |\n",
      "|    std                  | 0.985       |\n",
      "|    value_loss           | 2.8         |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=80000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CiBG2ZknsG73"
   },
   "source": [
    "### Model 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UcRdoBc8-Xze",
    "outputId": "cc0a65bf-f79d-48ce-c173-6ae08747b0fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 1000000, 'learning_rate': 0.0003}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 128, \n",
    "              \"buffer_size\": 1000000, \n",
    "              \"learning_rate\": 0.0003}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CB5cAAio-ZSs",
    "outputId": "741a1ed9-9bb0-4763-f237-5cd461ac100e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/td3\\td3_4\n",
      "day: 2515, episode: 70\n",
      "begin_total_asset:100000.00\n",
      "end_total_asset:100000.00\n",
      "total_reward:0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 214      |\n",
      "|    time_elapsed    | 46       |\n",
      "|    total timesteps | 10064    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.38e+03 |\n",
      "|    critic_loss     | 1.69e+04 |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7548     |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_td3 = agent.train_model(model=model_td3, \n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDk2qrlTLZCp"
   },
   "source": [
    "### Model 4: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "el8sK4fo-dl1",
    "outputId": "20c5793c-397b-4dc3-a702-857178e61813"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 100000,\n",
    "    \"learning_rate\": 0.00003,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gaF80PR0-d_d",
    "outputId": "b26b6435-ca69-4000-b2b3-22596677d8ff"
   },
   "outputs": [],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KE1Xm9N9TnTn"
   },
   "source": [
    "### Trading\n",
    "* we use the environment class we initialized at 5.3 to create a stock trading environment\n",
    "* Assume that we have $100,000 initial capital at 2019-01-01. \n",
    "* We use the trained model of PPO to trade AAPL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "kLFUwxhCoHN_",
    "outputId": "22540921-fc5e-460b-f9ef-1438131b45d7"
   },
   "outputs": [],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLHl6V7eqV6_"
   },
   "outputs": [],
   "source": [
    "## make a prediction and get the account value change\n",
    "#trade = data_split(data_df, start = '2019-01-01', end = '2020-09-23')\n",
    "\n",
    "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
    "\n",
    "df_account_value, df_actions = DRLAgent.DRL_prediction(model=trained_ppo,\n",
    "                                           test_data = trade,\n",
    "                                           test_env = env_trade,\n",
    "                                           test_obs = obs_trade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYXxFzD5TnTw"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtesting Performance\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GwqOO-v1NVz"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C9cpPm9YYxHC",
    "outputId": "7c7a8e34-7ed3-441d-9036-829240430843"
   },
   "outputs": [],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = BackTestStats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-Tenjb0hcNr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4Gw3HNr1TDU"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MA_8LuZE1J3X",
    "outputId": "3d2c46b2-2b6e-4cfd-9648-68ae7d37d89c"
   },
   "outputs": [],
   "source": [
    "print(\"==============Compare to AAPL itself buy-and-hold===========\")\n",
    "%matplotlib inline\n",
    "BackTestPlot(account_value=df_account_value, \n",
    "             baseline_ticker = 'AAPL',\n",
    "             baseline_start = '2019-01-01',\n",
    "             baseline_end = '2020-09-23')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSFMdgCJE4O-"
   },
   "source": [
    "<a id='6.3'></a>\n",
    "## 7.3 Baseline Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MpR7aQIwqdC4",
    "outputId": "24029a71-3596-4090-d7bc-7f44dd6000fc"
   },
   "outputs": [],
   "source": [
    "print(\"==============Get Baseline Stats===========\")\n",
    "baesline_perf_stats=BaselineStats('AAPL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vSFRXQfYFTQf",
    "outputId": "a5951bab-aa47-4fa8-9cd9-9fc62b5b02f5"
   },
   "outputs": [],
   "source": [
    "print(\"==============Get Baseline Stats===========\")\n",
    "baesline_perf_stats=BaselineStats('^GSPC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tunrA4mjE9la"
   },
   "source": [
    "<a id='6.4'></a>\n",
    "## 7.4 Compare to Stock Market Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5Ca2gHxi1gzX",
    "outputId": "68de7e8c-882a-4e8a-c9a9-cea8ea6ca212"
   },
   "outputs": [],
   "source": [
    "print(\"==============Compare to S&P 500===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "BackTestPlot(df_account_value, baseline_ticker = '^GSPC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_aHGEOTCluG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Y9CM5DeIr9GC",
    "9upN8FI2r_X1",
    "CiBG2ZknsG73"
   ],
   "include_colab_link": true,
   "name": "FinRL_single_stock_trading.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
